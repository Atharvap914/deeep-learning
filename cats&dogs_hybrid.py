# -*- coding: utf-8 -*-
"""cats&dogs_hybrid.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10L-hd9DI7VJvG21mpHunwf_LzpKc_24C
"""

from google.colab import files
files.upload()

import os
import zipfile

os.makedirs("/root/.kaggle", exist_ok = True)
!mv kaggle.json /root/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json

!kaggle datasets download -d samuelcortinhas/cats-and-dogs-image-classification

!unzip -q cats-and-dogs-image-classification.zip

!ls

train_dir = "/content/train"
test_dir = "/content/test"

train_dir

test_dir

os.listdir('/content/train/dogs')

len(os.listdir('/content/test'))

len(os.listdir('/content/train'))

image_count = sum(
    len(files)
    for _, _, files in os.walk('/content/train')
)

print(f"Total number of images in /content/train: {image_count}")

import shutil
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
import random
import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess
from tensorflow.keras.utils import image_dataset_from_directory

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from xgboost import XGBClassifier
from tensorflow.keras.models import Model
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.utils import load_img, img_to_array

load_img('/content/train/dogs/dog_378.jpg')

load_img('/content/train/dogs/dog_334.jpg')

BATCH_SIZE = 16
IMG_SIZE = (224, 224)

train_ds = tf.keras.utils.image_dataset_from_directory(train_dir,
                                                       shuffle = True,
                                                       batch_size = BATCH_SIZE,
                                                       image_size= IMG_SIZE)

train_ds.class_names
class_names = train_ds.class_names
class_names

test_ds = tf.keras.utils.image_dataset_from_directory(test_dir,
                                                                 shuffle=True,
                                                                 batch_size=BATCH_SIZE,
                                                                 image_size=IMG_SIZE)

class_names[1]

class_names[0]

data_augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomFlip("horizontal"),
    tf.keras.layers.RandomRotation(0.1),
    tf.keras.layers.RandomZoom(0.1)
])

for image, label in train_ds.take(1):
  print(image.shape)
  print(label)

plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")

# Phase 1 : Feature Extraction using a Pretrained CNN (RestNet50)



base_model = ResNet50(weights = 'imagenet',
                      include_top = False,
                      pooling = 'avg',
                      input_shape = (224,224,3))

base_model.summary()

def extract_features(dataset, model, augment = False):
  features = []
  labels = []
  for batch in dataset:   # this will return a batch with a batch of images, and their corresponding labels
    imgs, lbl = batch   #  this will split batch into imgs, and lbl
    if augment:
            imgs = data_augmentation(imgs)
    imgs = resnet_preprocess(imgs)   # this will apply ResNet-style preprocessing (like rescaling pixels, maybe mean subtraction)
    # Extract features using predict in a loop here.
    feats = model.predict(imgs)  # Runs imgs through the model â†’ outputs feature vectors (not final classification, but deep-layer representations)
    features.append(feats)
    labels.append(lbl.numpy())

  features = np.concatenate(features, axis = 0)   # Merges all batch-wise outputs into one big array
  labels = np.concatenate(labels, axis = 0)
  return features, labels

X_train, y_train = extract_features(train_ds, base_model, augment=True)
X_test, y_test = extract_features(test_ds, base_model, augment=True)

X_train.shape

# Phase 2 : Scaling and Dimensionality Reduction

# Scale Features

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Apply PCA for dimensionality reduction
# (Adjust n_components based on your needs, explaining ~98% of variance)


pca = PCA(n_components=99)
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)

X_train_pca.shape

X_test_pca.shape

xgb_model = XGBClassifier(
    objective='multi:softmax',  # for multiclass classification
    num_class=len(np.unique(y_train)),  # number of classes in your dataset
    eval_metric='mlogloss',
    use_label_encoder=False,
    random_state=42,
    n_estimators=250,
    max_depth=8,
    learning_rate=0.1
)

xgb_model.fit(X_train_pca, y_train)
y_pred = xgb_model.predict(X_test_pca)

# Phase 4: Evaluation Metrics


print("Classification Report:")
print(classification_report(y_test, y_pred))

img1 = tf.keras.utils.load_img("/content/images (1).jpeg", target_size=(224, 224))

img1

img_array = tf.keras.utils.img_to_array(img1)

img_array.shape

img_array = resnet_preprocess(img_array)

img_array = img_array.reshape(1,224,224,3)

img_array.shape

img_features = base_model.predict(img_array)

img_features.shape

scaled_feat = scaler.transform(img_features)

scaled_feat.shape

reduced_features = pca.transform(scaled_feat)

reduced_features.shape

predictions = xgb_model.predict(reduced_features)

predictions

predicted_index = np.argmax(predictions, axis=0)

predicted_name = class_names[predicted_index]

predicted_name

