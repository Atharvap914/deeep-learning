# -*- coding: utf-8 -*-
"""lung_pneumonia.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bCsZrHXKDZHhm2uiBMuOzN3dM5Cfm6Mt
"""

from google.colab import drive
drive.mount('/content/drive')

import zipfile
import os

# Specify the path to your zip file
zip_file_path = '/content/drive/My Drive/chest_xray.zip' # Make sure this is the correct path to your zip file

# Specify the directory where you want to extract the contents
extracted_path = '/tmp/chest_xray_extracted' # You can choose any directory path

# Create the extraction directory if it doesn't exist
os.makedirs(extracted_path, exist_ok=True)

# Unzip the file
if os.path.exists(zip_file_path):
    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
        zip_ref.extractall(extracted_path)
    print(f"Successfully extracted {zip_file_path} to {extracted_path}")

    # List the contents of the extracted directory to verify
    print(f"\nContents of the extracted directory '{extracted_path}':")
    for filename in os.listdir(extracted_path):
        print(filename)
else:
    print(f"Zip file not found at: {zip_file_path}")

"""# Task
Create a multi-hybrid model for image classification using the images in the directory "extracted_images".

## Data loading and exploration

### Subtask:
Load the images from the extracted directory and explore the dataset structure and image properties (e.g., size, format, number of classes).

**Reasoning**:
The previous code block successfully extracted the zip file to `/tmp/chest_xray_extracted`. The next step is to explore the extracted directory to understand the dataset structure, including the number of classes and images per class. I will iterate through the subdirectories and count the images.
"""

# Specify the path to the extracted dataset directory
extracted_dataset_path = '/tmp/chest_xray_extracted/chest_xray' # Based on the previous output, the actual data is in a subfolder

# List the contents of the main extracted directory
print(f"Contents of the dataset directory '{extracted_dataset_path}':")
dataset_contents = os.listdir(extracted_dataset_path)
print(dataset_contents)

# Initialize a dictionary to store image counts per class
class_image_counts = {}
total_images = 0
sample_images = {}

# Iterate through the subdirectories (presumably representing different classes)
print("\nExploring class directories:")
for class_name in dataset_contents:
    class_dir_path = os.path.join(extracted_dataset_path, class_name)

    # Check if the item is a directory
    if os.path.isdir(class_dir_path):
        print(f"  Class directory: {class_name}")
        try:
            # List the files (images) within the class directory
            image_files = [f for f in os.listdir(class_dir_path) if os.path.isfile(os.path.join(class_dir_path, f))]

            # Count the number of images in the subdirectory
            num_images = len(image_files)
            class_image_counts[class_name] = num_images
            total_images += num_images

            # Select a few sample images from this class
            if num_images > 0:
                sample_images[class_name] = image_files[:3] # Take up to the first 3 images

        except Exception as e:
            print(f"    Error listing files in {class_dir_path}: {e}")
    else:
        print(f"  Skipping non-directory item: {class_name}")


# Print the total number of images and the number of images per class
print("\nDataset Summary:")
print(f"Total number of images: {total_images}")
print("Number of images per class:")
for class_name, count in class_image_counts.items():
    print(f"  {class_name}: {count}")

# Print sample image filenames
print("\nSample image filenames per class:")
for class_name, filenames in sample_images.items():
    print(f"  {class_name}: {filenames}")

"""**Reasoning**:
The previous step showed that the actual image data is likely within subdirectories like 'train', 'test', and 'val' inside the '/tmp/chest_xray_extracted/chest_xray' folder, but the counts were zero for train, test, and val, and there were unexpected files like `.DS_Store` and `._chest_xray`. This suggests there's another level of directories or the previous listing was incomplete. I need to explore the subdirectories within 'train', 'test', and 'val' to find the actual class folders (like 'NORMAL' and 'PNEUMONIA') and count the images there. I will also examine the image properties of a sample image.


"""

from PIL import Image
import numpy as np

# Define the main dataset directory
main_dataset_dir = '/tmp/chest_xray_extracted/chest_xray'

# Initialize dictionaries for counts and sample images
class_image_counts_per_split = {}
sample_images_per_split = {}
total_images_in_splits = 0

# Define the expected data splits
data_splits = ['train', 'test', 'val']

print(f"Exploring data splits within '{main_dataset_dir}':")

for split in data_splits:
    split_dir_path = os.path.join(main_dataset_dir, split)
    class_image_counts_per_split[split] = {}
    sample_images_per_split[split] = {}

    if os.path.isdir(split_dir_path):
        print(f"\n  Exploring split: {split}")
        split_contents = os.listdir(split_dir_path)
        print(f"    Contents of '{split_dir_path}': {split_contents}")

        for class_name in split_contents:
            class_dir_path = os.path.join(split_dir_path, class_name)

            # Check if the item is a directory and not a hidden directory like __MACOSX
            if os.path.isdir(class_dir_path) and not class_name.startswith('__'):
                print(f"    Class directory within {split}: {class_name}")
                try:
                    # List the files (images) within the class directory
                    image_files = [f for f in os.listdir(class_dir_path) if os.path.isfile(os.path.join(class_dir_path, f)) and f.lower().endswith(('.png', '.jpg', '.jpeg'))]

                    # Count the number of images
                    num_images = len(image_files)
                    class_image_counts_per_split[split][class_name] = num_images
                    total_images_in_splits += num_images

                    # Select a few sample images from this class
                    if num_images > 0:
                        sample_images_per_split[split][class_name] = image_files[:3] # Take up to the first 3 images

                        # Examine properties of a sample image (only for the first encountered image)
                        if 'sample_image_properties' not in locals():
                            sample_image_path = os.path.join(class_dir_path, image_files[0])
                            try:
                                with Image.open(sample_image_path) as img:
                                    sample_image_properties = {
                                        'path': sample_image_path,
                                        'format': img.format,
                                        'mode': img.mode,
                                        'size': img.size,
                                        'class': class_name,
                                        'split': split
                                    }
                                print(f"      Sample image properties from '{sample_image_path}': {sample_image_properties}")
                            except Exception as img_e:
                                print(f"      Error opening sample image {sample_image_path}: {img_e}")


                except Exception as e:
                    print(f"      Error listing files in {class_dir_path}: {e}")
            else:
                 if not class_name.startswith('__'): # Avoid printing for __MACOSX again
                    print(f"    Skipping non-directory or hidden item in {split}: {class_name}")

    else:
        print(f"  Split directory not found: {split_dir_path}")


# Print the dataset structure and counts
print("\nDataset Structure and Summary:")
print(f"Total number of images across train, test, and val splits: {total_images_in_splits}")
print("\nImage counts per class per split:")
for split, class_counts in class_image_counts_per_split.items():
    print(f"  {split.upper()} Split:")
    if class_counts:
        for class_name, count in class_counts.items():
            print(f"    {class_name}: {count}")
    else:
        print("    No image directories found.")

# Print sample image filenames
print("\nSample image filenames per class per split:")
for split, class_samples in sample_images_per_split.items():
    print(f"  {split.upper()} Split:")
    if class_samples:
        for class_name, filenames in class_samples.items():
            print(f"    {class_name}: {filenames}")
    else:
        print("    No sample images found.")

# Print the properties of the examined sample image
if 'sample_image_properties' in locals():
    print("\nProperties of a sample image:")
    print(f"  Path: {sample_image_properties['path']}")
    print(f"  Format: {sample_image_properties['format']}")
    print(f"  Mode: {sample_image_properties['mode']}")
    print(f"  Size: {sample_image_properties['size']}")
    print(f"  Class: {sample_image_properties['class']}")
    print(f"  Split: {sample_image_properties['split']}")
else:
    print("\nNo sample image properties could be determined.")

"""## Data preprocessing

### Subtask:
Prepare the images for model training, which may include resizing, normalization, and data augmentation.

**Reasoning**:
Use Keras ImageDataGenerator to create data generators for training, validation, and test sets. This will handle resizing, normalization, and data augmentation.
"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define target image dimensions
IMG_HEIGHT = 150
IMG_WIDTH = 150
IMAGE_SIZE = (IMG_WIDTH, IMG_HEIGHT)
BATCH_SIZE = 32

# Define the main dataset directory
main_dataset_dir = '/tmp/chest_xray_extracted/chest_xray'
train_dir = os.path.join(main_dataset_dir, 'train')
validation_dir = os.path.join(main_dataset_dir, 'val')
test_dir = os.path.join(main_dataset_dir, 'test')


# Create data generators with augmentation and normalization
# Rescale pixel values to [0, 1]
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Only rescale for validation and test sets (no augmentation)
validation_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

# Flow images from directories
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary' # Since we have two classes (NORMAL, PNEUMONIA)
)

validation_generator = validation_datagen.flow_from_directory(
    validation_dir,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary'
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary'
)

print("Train generator class indices:", train_generator.class_indices)
print("Validation generator class indices:", validation_generator.class_indices)
print("Test generator class indices:", test_generator.class_indices)

"""## Model architecture design

### Subtask:
Define the architecture of your multi-hybrid model. This could involve combining different types of layers or pre-trained models.

**Reasoning**:
Import the necessary libraries for building a hybrid model, including Keras layers and a pre-trained base like VGG16.
"""

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, concatenate
from tensorflow.keras.applications import VGG16

"""**Reasoning**:
Define the architecture of the multi-hybrid model, combining a VGG16 convolutional base with custom layers for binary classification.


"""

# Define the input shape
input_shape = (IMG_HEIGHT, IMG_WIDTH, 3) # Assuming images are RGB

# Load the VGG16 model with pre-trained weights, excluding the top classification layer
vgg = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)

# Freeze the convolutional base to prevent weights from being updated during training
vgg.trainable = False

# Create a custom model on top of the VGG16 base
input_tensor = Input(shape=input_shape)

# Use the VGG16 model as the convolutional base
x = vgg(input_tensor, training=False) # Set training=False to keep VGG16 layers in inference mode

# Add custom layers for classification
x = Flatten()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
output_tensor = Dense(1, activation='sigmoid')(x) # Binary classification

# Create the hybrid model
model = Model(inputs=input_tensor, outputs=output_tensor)

# Print the model summary
model.summary()

"""## Model compilation

### Subtask:
Configure the model for training by specifying the optimizer, loss function, and metrics.

**Reasoning**:
Import necessary components from tensorflow.keras and compile the model with the specified optimizer, loss function, and metrics.
"""

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.metrics import Accuracy

# Compile the model
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Print the model configuration after compilation to verify
print("Model compiled successfully.")
print("Optimizer:", model.optimizer.get_config()['name'])
print("Loss function:", model.loss)
print("Metrics:", [metric.name for metric in model.metrics])

"""## Model training

### Subtask:
Train the model on your prepared dataset.

**Reasoning**:
Train the compiled model using the prepared data generators and store the training history.
"""

import time

# Define the number of training epochs
EPOCHS = 3

print(f"Starting model training for {EPOCHS} epochs...")
start_time = time.time()

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // BATCH_SIZE,
    epochs=EPOCHS,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // BATCH_SIZE
)

end_time = time.time()
print(f"Model training finished after {end_time - start_time:.2f} seconds.")

# The training history is now stored in the 'history' variable.

"""## Model Evaluation

### Subtask:
Evaluate the trained model's performance using appropriate metrics.

**Reasoning**:
Evaluate the trained model on the test dataset using the `evaluate` method and print the results.
"""

# Evaluate the model on the test set
print("Evaluating the model on the test dataset...")
test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // BATCH_SIZE)

print(f"\nTest Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

"""# Task
Create a Streamlit frontend for a trained Keras multi-hybrid model that takes an image file path as input and outputs the model's prediction.

## Install streamlit

### Subtask:
Install the Streamlit library in your environment.

**Reasoning**:
Install the streamlit library using pip.
"""

!pip install streamlit

"""## Save the trained model

### Subtask:
Save your trained Keras model to a file so it can be loaded in the Streamlit application.

**Reasoning**:
Save the trained Keras model to a file.
"""

import os

# Define the directory path where you want to save the model
# Using the current working directory
save_dir = '.'

# Construct the full path for the model file
model_filename = 'multi_hybrid_model.h5'
model_path = os.path.join(save_dir, model_filename)

# Save the trained model
model.save(model_path)

# Print a confirmation message
print(f"Model saved successfully to: {model_path}")

"""## Create a streamlit app file

### Subtask:
Write the Python code for your Streamlit application.

**Reasoning**:
Write the initial structure of the Streamlit application in a Python file, including necessary imports and a title, as outlined in the instructions.
"""

# app.py

import streamlit as st
import tensorflow as tf
from tensorflow.keras.models import load_model
from PIL import Image
import numpy as np
import os

# Set up the basic structure of the Streamlit app
st.title("Chest X-Ray Pneumonia Classifier")

# Add comments to outline the different sections of the app
# Section 1: Model Loading
# Section 2: File Uploader and Image Display
# Section 3: Image Preprocessing
# Section 4: Prediction
# Section 5: Displaying Results

"""**Reasoning**:
Add the model loading section to the Streamlit application, loading the previously saved Keras model.


"""

# Section 1: Model Loading
# Define the path to the saved model
model_path = 'multi_hybrid_model.h5' # Ensure this matches the path where you saved the model

# Load the trained model
@st.cache_resource # Cache the model to avoid reloading on each rerun
def load_my_model():
    try:
        model = load_model(model_path)
        return model
    except Exception as e:
        st.error(f"Error loading the model: {e}")
        return None

model = load_my_model()

if model is not None:
    st.success("Model loaded successfully!")
else:
    st.stop() # Stop the app if the model fails to load

"""**Reasoning**:
Add the file uploader and image display section to the Streamlit application, allowing users to upload an image and displaying it.

## Load the model

### Subtask:
In the Streamlit app, load the saved Keras model.

**Reasoning**:
Import necessary libraries and define the function to load the Keras model with caching.

## Create file uploader

### Subtask:
Add a component to the Streamlit app to allow users to upload an image file.

**Reasoning**:
Add a file uploader widget to the Streamlit app code using `st.file_uploader` and configure it to accept common image file types.

## Preprocess the image

### Subtask:
Write code to preprocess the uploaded image to match the input requirements of your model (resizing, normalization, etc.).

## Make a prediction

### Subtask:
Use the loaded model to make a prediction on the preprocessed image.

**Reasoning**:
Use the loaded model to make a prediction on the preprocessed image array and extract the prediction probability for the positive class.

**Reasoning**:
The error indicates that `img_array` is not defined in the current scope. This is because the code for preprocessing the image, which defines `img_array`, was in a previous code block and needs to be included in the current script context. I will regenerate the complete Streamlit app code including the model loading, file uploader, image preprocessing, and prediction steps in a single code block to ensure all necessary variables are defined.

## Display the result

### Subtask:
Show the uploaded image and the model's prediction in the Streamlit app.

## Run the streamlit app

### Subtask:
Provide instructions on how to run the Streamlit application.

## Summary:

### Data Analysis Key Findings

*   The trained Keras model was successfully saved to `./multi_hybrid_model.h5` using the legacy HDF5 format, although the newer `.keras` format was recommended.
*   A Streamlit application script (`app.py`) was created that includes functionality for loading the saved Keras model using caching (`@st.cache_resource`), handling image file uploads (`st.file_uploader`), displaying the uploaded image (`st.image`), preprocessing the image (resizing, converting to NumPy array, handling grayscale, adding batch dimension, normalization), making predictions using the loaded model (`model.predict`), and displaying the prediction results (`st.subheader`, `st.error`, `st.success`) with confidence levels.
*   The image preprocessing steps correctly resize images to 150x150 pixels, convert them to NumPy arrays, ensure they have 3 color channels (converting grayscale to RGB if necessary), add a batch dimension, and normalize pixel values to the range [0, 1].
*   The prediction display logic correctly identifies "PNEUMONIA" for prediction probabilities greater than 0.5 and "NORMAL" otherwise, displaying the corresponding confidence.
*   The Streamlit application includes error handling for model loading failures and unsupported image formats.
*   Instructions were provided on how to run the Streamlit application from the command line using `streamlit run app.py`.

### Insights or Next Steps

*   Consider updating the model saving format from HDF5 (`.h5`) to the recommended Keras native format (`.keras`) for potential future compatibility and performance benefits.
*   Enhance the user interface by adding a spinner or progress bar during the prediction phase to provide better feedback to the user while the model is processing the image.

## Run the Streamlit app

### Subtask:
Provide instructions on how to run the Streamlit application.

After saving the code to `app.py`, run the following command in a new code cell (or a Colab terminal):

This command does the following:
- `!streamlit run app.py`: Runs your Streamlit application.
- `&`: Allows the Streamlit process to run in the background.
- `npx localtunnel --port 8501`: Exposes the Streamlit app (which runs on port 8501 by default) to the internet via a temporary public URL, so you can access it from your browser.

You will see an output with a public URL (something like `https://<random-subdomain>.loca.lt`). Click on this URL to open your Streamlit application in a new tab.
"""